# Speech Emotion Recognition


## Objective
As emotions play a vital role in communication, the detection and analysis of the same is of vital importance in today’s digital world of remote communication. Emotion detection is a challenging task, because emotions are subjective. There is no common consensus on how to measure or categorize them. 

There are three classes of features in a speech :

- The lexical features (the vocabulary used)
- The visual features (the expressions the speaker makes) 
- The acoustic features (sound properties like pitch, tone, jitter, etc.)

The problem of speech emotion recognition can be solved by analysing one or more of these features. Choosing to follow the lexical features would require additional step of text extraction from speech,similarly analysing visual features would require the excess to video of the conversations which might not be feasible in every case,while the analysis on the acoustic features can be done in real-time while the conversation is taking place as we’d just need the audio data for accomplishing our task.The main goal of this project is to build a speech emotion detection system,which can optimally classify a user's speech by analysing the patterns in audio.
